name: CI

on:
  push:
    branches: [main]
  pull_request:
    types: [opened, synchronize, reopened]
  workflow_dispatch:
    inputs:
      run_benchmarks:
        description: 'Run performance benchmarks'
        type: boolean
        default: false
      run_integration:
        description: 'Run integration tests'
        type: boolean
        default: false

jobs:
  build:
    name: Build
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup .NET
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: '10.0.x'

      - name: Cache NuGet
        uses: actions/cache@v4
        with:
          path: ~/.nuget/packages
          key: ${{ runner.os }}-nuget-${{ hashFiles('**/*.csproj') }}
          restore-keys: ${{ runner.os }}-nuget-

      - name: Restore
        run: dotnet restore

      - name: Build
        run: dotnet build --no-restore

  architecture:
    name: Architecture Tests
    needs: build
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup .NET
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: '10.0.x'

      - name: Cache NuGet
        uses: actions/cache@v4
        with:
          path: ~/.nuget/packages
          key: ${{ runner.os }}-nuget-${{ hashFiles('**/*.csproj') }}
          restore-keys: ${{ runner.os }}-nuget-

      - name: Restore and Build
        run: dotnet restore && dotnet build --no-restore

      - name: Run Architecture Tests
        id: arch
        run: |
          mkdir -p artifacts/architecture
          FAILED=0
          for project in $(find tests/ArchitectureTests -name "*.csproj"); do
            name=$(basename "$(dirname "$project")")
            echo "::group::Architecture tests for $name"
            dotnet test "$project" --no-build \
              --logger "trx;LogFileName=architecture-${name}.trx" \
              --results-directory "artifacts/architecture" || FAILED=1
            echo "::endgroup::"
          done
          echo "failed=$FAILED" >> $GITHUB_OUTPUT

      - name: Upload Architecture Results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: architecture-results
          path: artifacts/architecture/
          retention-days: 1
          if-no-files-found: ignore

    outputs:
      failed: ${{ steps.arch.outputs.failed }}

  unit-test:
    name: Unit Tests & SonarCloud
    needs: architecture
    runs-on: ubuntu-latest

    steps:
      - name: Set up JDK 17
        uses: actions/setup-java@v4
        with:
          java-version: 17
          distribution: 'zulu'

      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup .NET
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: '10.0.x'

      - name: Cache NuGet
        uses: actions/cache@v4
        with:
          path: ~/.nuget/packages
          key: ${{ runner.os }}-nuget-${{ hashFiles('**/*.csproj') }}
          restore-keys: ${{ runner.os }}-nuget-

      - name: Cache SonarCloud packages
        uses: actions/cache@v4
        with:
          path: ~/.sonar/cache
          key: ${{ runner.os }}-sonar
          restore-keys: ${{ runner.os }}-sonar

      - name: Install tools
        run: |
          dotnet tool install --global dotnet-sonarscanner
          dotnet tool install --global dotnet-coverage

      - name: Restore and Build
        run: dotnet restore && dotnet build --no-restore

      - name: Begin SonarCloud analysis
        env:
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
        run: |
          dotnet sonarscanner begin \
            /k:"CasteloBrancoLab_Bedrock" \
            /o:"castelobrancolab" \
            /d:sonar.token="${SONAR_TOKEN}" \
            /d:sonar.cs.vscoveragexml.reportsPaths="coverage/coverage.xml" \
            /d:sonar.exclusions="**/tests/**/*,**/scripts/**/*,**/obj/**/*,**/bin/**/*,**/samples/**/*,**/templates/**/*,**/tools/**/*,**/playground/**/*,**/src/BuildingBlocks/Testing/Benchmarks/**/*,**/src/BuildingBlocks/Testing/Integration/**/*,**/src/BuildingBlocks/Testing/Attributes/**/*,**/src/BuildingBlocks/Testing/TestBase.cs,**/src/BuildingBlocks/Testing/ServiceCollectionFixture.cs,**/Migrations/Scripts/**/*.sql" \
            /d:sonar.coverage.exclusions="**/tests/**/*,**/samples/**/*,**/templates/**/*,**/tools/**/*,**/playground/**/*,**/src/BuildingBlocks/Testing/Benchmarks/**/*,**/src/BuildingBlocks/Testing/Integration/**/*,**/src/BuildingBlocks/Testing/Attributes/**/*,**/src/BuildingBlocks/Testing/TestBase.cs,**/src/BuildingBlocks/Testing/ServiceCollectionFixture.cs" \
            /d:sonar.cpd.exclusions="**/Serialization.Avro/AvroSerializerBase.cs,**/Serialization.Protobuf/ProtobufSerializerBase.cs,**/Serialization.Parquet/ParquetSerializerBase.cs"

      - name: Build (SonarCloud instrumented)
        run: dotnet build --no-restore

      - name: Test with coverage
        id: test
        run: |
          mkdir -p artifacts/coverage/raw

          FAILED=0
          for project in $(find tests/UnitTests -name "*.csproj"); do
            name=$(echo "$project" | sed 's|tests/UnitTests/||' | sed 's|/[^/]*\.csproj$||' | sed 's|/|.|g')
            echo "::group::Unit tests for $name"

            dotnet-coverage collect "dotnet test --no-build $project --logger trx;LogFileName=results.trx --results-directory artifacts/coverage/raw/$name" \
              -f cobertura \
              -o "artifacts/coverage/raw/$name.cobertura.xml" || FAILED=1

            echo "::endgroup::"
          done
          echo "failed=$FAILED" >> $GITHUB_OUTPUT

      - name: Merge coverage for SonarCloud
        if: always()
        run: |
          mkdir -p coverage
          dotnet-coverage merge artifacts/coverage/raw/*.cobertura.xml \
            -f xml \
            -o coverage/coverage.xml || true

      - name: End SonarCloud analysis
        if: always()
        env:
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
        run: dotnet sonarscanner end /d:sonar.token="${SONAR_TOKEN}"

      - name: Upload Coverage Results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: coverage-results
          path: artifacts/coverage/raw/
          retention-days: 1
          if-no-files-found: ignore

    outputs:
      failed: ${{ steps.test.outputs.failed }}

  mutation:
    name: Mutation Tests
    needs: unit-test
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup .NET
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: '10.0.x'

      - name: Cache NuGet
        uses: actions/cache@v4
        with:
          path: ~/.nuget/packages
          key: ${{ runner.os }}-nuget-${{ hashFiles('**/*.csproj') }}
          restore-keys: ${{ runner.os }}-nuget-

      - name: Restore and Build
        run: dotnet restore && dotnet build --no-restore

      - name: Install Stryker
        run: dotnet tool install --global dotnet-stryker

      - name: Run Mutation Tests
        id: mutation
        run: |
          mkdir -p artifacts/mutation
          FAILED=0
          SUMMARY=""

          for config in $(find tests/MutationTests -name "stryker-config.json"); do
            DIR=$(dirname "$config")
            NAME=$(basename "$DIR")
            echo "::group::Running mutation tests for $NAME"

            cd "$DIR"

            STRYKER_OUTPUT=$(dotnet stryker -O "$GITHUB_WORKSPACE/artifacts/mutation/$NAME" --reporter json --reporter progress 2>&1) || true
            STRYKER_EXIT=$?
            echo "$STRYKER_OUTPUT"

            if echo "$STRYKER_OUTPUT" | grep -q "No mutants were generated"; then
              echo "::notice::No mutatable code found in $NAME - skipping"
              SUMMARY="${SUMMARY}| ${NAME} | :white_check_mark: Skipped (no mutatable code) |\n"
            elif [ $STRYKER_EXIT -eq 0 ]; then
              SUMMARY="${SUMMARY}| ${NAME} | :white_check_mark: Passed |\n"
            else
              SUMMARY="${SUMMARY}| ${NAME} | :x: Failed |\n"
              FAILED=1
            fi
            cd "$GITHUB_WORKSPACE"

            echo "::endgroup::"
          done

          echo "summary<<EOF" >> $GITHUB_OUTPUT
          echo -e "$SUMMARY" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          echo "failed=$FAILED" >> $GITHUB_OUTPUT

      - name: Upload Mutation Results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: mutation-results
          path: artifacts/mutation/
          retention-days: 1
          if-no-files-found: ignore

    outputs:
      failed: ${{ steps.mutation.outputs.failed }}
      summary: ${{ steps.mutation.outputs.summary }}

  integration:
    name: Integration Tests
    needs: mutation
    if: ${{ inputs.run_integration == true }}
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup .NET
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: '10.0.x'

      - name: Cache NuGet
        uses: actions/cache@v4
        with:
          path: ~/.nuget/packages
          key: ${{ runner.os }}-nuget-${{ hashFiles('**/*.csproj') }}
          restore-keys: ${{ runner.os }}-nuget-

      - name: Restore and Build
        run: dotnet restore && dotnet build --no-restore

      - name: Run Integration Tests
        id: integration
        run: |
          mkdir -p artifacts/test-results
          FAILED=0
          for project in $(find tests/IntegrationTests -name "*.csproj"); do
            name=$(basename "$(dirname "$project")")
            echo "::group::Integration tests for $name"
            dotnet test "$project" --no-build \
              --logger "trx;LogFileName=integration-$name.trx" \
              --results-directory "artifacts/test-results" || FAILED=1
            echo "::endgroup::"
          done
          echo "failed=$FAILED" >> $GITHUB_OUTPUT

      - name: Upload Integration Results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: integration-results
          path: artifacts/test-results/
          retention-days: 1
          if-no-files-found: ignore

    outputs:
      failed: ${{ steps.integration.outputs.failed }}

  benchmarks:
    name: Benchmarks
    needs: mutation
    if: ${{ inputs.run_benchmarks == true }}
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup .NET
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: '10.0.x'

      - name: Cache NuGet
        uses: actions/cache@v4
        with:
          path: ~/.nuget/packages
          key: ${{ runner.os }}-nuget-${{ hashFiles('**/*.csproj') }}
          restore-keys: ${{ runner.os }}-nuget-

      - name: Build (Release)
        run: |
          dotnet restore
          for project in $(find tests/PerformanceTests -name "*.csproj"); do
            dotnet build "$project" -c Release --no-restore
          done

      - name: Run Benchmarks
        id: bench
        run: |
          mkdir -p artifacts/benchmark
          FAILED=0
          for project in $(find tests/PerformanceTests -name "*.csproj"); do
            name=$(basename "$(dirname "$project")")
            echo "::group::Benchmarks for $name"
            dotnet run --project "$project" -c Release --no-build || FAILED=1
            echo "::endgroup::"
          done
          # Copy benchmark files from pending (where SustainedBenchmarkRunner outputs)
          if [ -d "artifacts/pending" ]; then
            cp -f artifacts/pending/benchmark_*.txt artifacts/benchmark/ 2>/dev/null || true
            cp -f artifacts/pending/benchmark_*_samples.json artifacts/benchmark/ 2>/dev/null || true
          fi
          echo "failed=$FAILED" >> $GITHUB_OUTPUT

      - name: Upload Benchmark Results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: benchmark-results
          path: artifacts/benchmark/
          retention-days: 1
          if-no-files-found: warn

    outputs:
      failed: ${{ steps.bench.outputs.failed }}

  reports:
    name: Generate Reports
    needs: [mutation, integration, benchmarks]
    if: ${{ always() && !cancelled() }}
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup .NET
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: '10.0.x'

      - name: Cache NuGet
        uses: actions/cache@v4
        with:
          path: ~/.nuget/packages
          key: ${{ runner.os }}-nuget-${{ hashFiles('**/*.csproj') }}
          restore-keys: ${{ runner.os }}-nuget-

      - name: Restore
        run: dotnet restore

      - name: Download Architecture Results
        uses: actions/download-artifact@v4
        with:
          name: architecture-results
          path: artifacts/architecture/
        continue-on-error: true

      - name: Download Coverage Results
        uses: actions/download-artifact@v4
        with:
          name: coverage-results
          path: artifacts/coverage/raw/
        continue-on-error: true

      - name: Download Mutation Results
        uses: actions/download-artifact@v4
        with:
          name: mutation-results
          path: artifacts/mutation/
        continue-on-error: true

      - name: Download Integration Results
        uses: actions/download-artifact@v4
        if: ${{ needs.integration.result == 'success' || needs.integration.result == 'failure' }}
        with:
          name: integration-results
          path: artifacts/test-results/
        continue-on-error: true

      - name: Download Benchmark Results
        uses: actions/download-artifact@v4
        if: ${{ needs.benchmarks.result == 'success' || needs.benchmarks.result == 'failure' }}
        with:
          name: benchmark-results
          path: artifacts/benchmark/
        continue-on-error: true

      - name: Generate Architecture Report
        run: |
          ./scripts/generate-architecture-report.sh || true

      - name: Generate Unit Test Report
        run: |
          ./scripts/generate-unittest-report.sh || true

      - name: Generate Integration Report
        if: ${{ needs.integration.result == 'success' || needs.integration.result == 'failure' }}
        run: |
          ./scripts/generate-integration-report.sh || true

      - name: Generate Benchmark Report
        if: ${{ needs.benchmarks.result == 'success' || needs.benchmarks.result == 'failure' }}
        run: |
          ./scripts/generate-benchmark-report.sh || true

      - name: Upload Architecture Report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: architecture-report
          path: artifacts/architecture-report/
          retention-days: 1
          if-no-files-found: ignore

      - name: Upload Unit Test Report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: unittest-report
          path: artifacts/unittest-report/
          retention-days: 1
          if-no-files-found: ignore

      - name: Upload Mutation Reports
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: mutation-reports
          path: artifacts/mutation/
          retention-days: 1
          if-no-files-found: ignore

      - name: Upload Integration Report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: integration-report
          path: artifacts/integration-report/
          retention-days: 1
          if-no-files-found: ignore

      - name: Upload Benchmark Report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: benchmark-report
          path: artifacts/benchmark-report/
          retention-days: 1
          if-no-files-found: ignore

  check:
    name: Pipeline Check
    needs: [architecture, unit-test, mutation, integration, benchmarks, reports]
    if: ${{ always() && !cancelled() }}
    runs-on: ubuntu-latest

    steps:
      - name: Evaluate Results
        env:
          MUTATION_SUMMARY: ${{ needs.mutation.outputs.summary }}
          RUN_URL: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
        run: |
          FAILED=0

          # Collect results
          ARCH="${{ needs.architecture.outputs.failed }}"
          UNIT="${{ needs.unit-test.outputs.failed }}"
          MUT="${{ needs.mutation.outputs.failed }}"
          INT_RESULT="${{ needs.integration.result }}"
          INT="${{ needs.integration.outputs.failed }}"
          BENCH_RESULT="${{ needs.benchmarks.result }}"
          BENCH="${{ needs.benchmarks.outputs.failed }}"
          REPORTS_RESULT="${{ needs.reports.result }}"

          [ "$ARCH" = "1" ] && FAILED=1
          [ "$UNIT" = "1" ] && FAILED=1
          [ "$MUT" = "1" ] && FAILED=1
          [ "$INT_RESULT" = "success" ] || [ "$INT_RESULT" = "failure" ] && [ "$INT" = "1" ] && FAILED=1
          [ "$BENCH_RESULT" = "success" ] || [ "$BENCH_RESULT" = "failure" ] && [ "$BENCH" = "1" ] && FAILED=1

          # Helper
          status_icon() {
            case "$1" in
              pass) echo ":white_check_mark:" ;;
              fail) echo ":x:" ;;
              skip) echo ":next_track_button:" ;;
              warn) echo ":warning:" ;;
            esac
          }
          job_status() {
            local result="$1" failed="$2"
            if [ "$result" = "skipped" ]; then echo "skip"
            elif [ "$failed" = "1" ]; then echo "fail"
            else echo "pass"
            fi
          }

          ARCH_S=$(job_status "ran" "$ARCH")
          UNIT_S=$(job_status "ran" "$UNIT")
          MUT_S=$(job_status "ran" "$MUT")
          [ "$INT_RESULT" = "skipped" ] && INT_S="skip" || INT_S=$(job_status "ran" "$INT")
          [ "$BENCH_RESULT" = "skipped" ] && BENCH_S="skip" || BENCH_S=$(job_status "ran" "$BENCH")
          [ "$REPORTS_RESULT" = "failure" ] && REP_S="warn" || REP_S="pass"

          # ── Header ──
          if [ $FAILED -eq 0 ]; then
            echo "# :rocket: Bedrock CI — All checks passed" >> $GITHUB_STEP_SUMMARY
          else
            echo "# :rotating_light: Bedrock CI — Pipeline failed" >> $GITHUB_STEP_SUMMARY
          fi
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "> **Branch:** \`${{ github.head_ref || github.ref_name }}\` · **Commit:** \`${GITHUB_SHA::7}\` · **Triggered by:** ${{ github.event_name }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # ── Pipeline Status ──
          echo "### Pipeline" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Stage | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|-------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| :building_construction: Build | $(status_icon pass) Passed |" >> $GITHUB_STEP_SUMMARY
          echo "| :classical_building: Architecture Tests | $(status_icon $ARCH_S) $([ "$ARCH_S" = "pass" ] && echo "Passed" || echo "**Failed**") |" >> $GITHUB_STEP_SUMMARY
          echo "| :test_tube: Unit Tests & SonarCloud | $(status_icon $UNIT_S) $([ "$UNIT_S" = "pass" ] && echo "Passed" || echo "**Failed**") |" >> $GITHUB_STEP_SUMMARY
          echo "| :dna: Mutation Tests | $(status_icon $MUT_S) $([ "$MUT_S" = "pass" ] && echo "Passed" || echo "**Failed**") |" >> $GITHUB_STEP_SUMMARY

          if [ "$INT_S" = "skip" ]; then
            echo "| :electric_plug: Integration Tests | $(status_icon skip) Skipped |" >> $GITHUB_STEP_SUMMARY
          else
            echo "| :electric_plug: Integration Tests | $(status_icon $INT_S) $([ "$INT_S" = "pass" ] && echo "Passed" || echo "**Failed**") |" >> $GITHUB_STEP_SUMMARY
          fi

          if [ "$BENCH_S" = "skip" ]; then
            echo "| :chart_with_upwards_trend: Benchmarks | $(status_icon skip) Skipped |" >> $GITHUB_STEP_SUMMARY
          else
            echo "| :chart_with_upwards_trend: Benchmarks | $(status_icon $BENCH_S) $([ "$BENCH_S" = "pass" ] && echo "Passed" || echo "**Failed**") |" >> $GITHUB_STEP_SUMMARY
          fi

          echo "| :bar_chart: Reports | $(status_icon $REP_S) $([ "$REP_S" = "pass" ] && echo "Generated" || echo "Errors during generation") |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # ── Mutation Details ──
          if [ -n "$MUTATION_SUMMARY" ]; then
            echo "<details><summary>:dna: Mutation Tests — Details per project</summary>" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "| Project | Status |" >> $GITHUB_STEP_SUMMARY
            echo "|---------|--------|" >> $GITHUB_STEP_SUMMARY
            echo -e "$MUTATION_SUMMARY" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "</details>" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          fi

          # ── Reports & Artifacts ──
          echo "### :package: Reports" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "HTML reports are available as artifacts in this run (retention: 24h):" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Report | Artifact |" >> $GITHUB_STEP_SUMMARY
          echo "|--------|----------|" >> $GITHUB_STEP_SUMMARY
          echo "| :classical_building: Architecture | \`architecture-report\` |" >> $GITHUB_STEP_SUMMARY
          echo "| :test_tube: Unit Tests & Coverage | \`unittest-report\` |" >> $GITHUB_STEP_SUMMARY
          echo "| :dna: Mutation (Stryker) | \`mutation-reports\` |" >> $GITHUB_STEP_SUMMARY

          if [ "$INT_RESULT" != "skipped" ]; then
            echo "| :electric_plug: Integration | \`integration-report\` |" >> $GITHUB_STEP_SUMMARY
          fi
          if [ "$BENCH_RESULT" != "skipped" ]; then
            echo "| :chart_with_upwards_trend: Benchmarks | \`benchmark-report\` |" >> $GITHUB_STEP_SUMMARY
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "> :bulb: Download artifacts from the [Actions run page]($RUN_URL) → **Artifacts** section at the bottom." >> $GITHUB_STEP_SUMMARY

          # ── Fail if needed ──
          if [ $FAILED -eq 1 ]; then
            echo "::error::Pipeline failed — see summary above"
            exit 1
          fi
